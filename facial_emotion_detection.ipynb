{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skcRr2ZDbS3M"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from deepface import DeepFace\n",
        "from IPython.display import display, clear_output\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# Initialize video capture from webcam\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "\n",
        "# Run for a fixed number of frames or until interruption\n",
        "frame_count = 0\n",
        "max_frames = 100  # adjust this if you want a longer or shorter run\n",
        "\n",
        "while frame_count < max_frames:\n",
        "    ret, frame = video_capture.read()\n",
        "\n",
        "    if not ret:\n",
        "        print(\"Failed to capture frame\")\n",
        "        break\n",
        "\n",
        "    # Convert frame to RGB (DeepFace requires RGB)\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    try:\n",
        "        # Analyze emotion\n",
        "        analysis = DeepFace.analyze(rgb_frame, actions=['emotion'], enforce_detection=False)\n",
        "\n",
        "        if analysis and isinstance(analysis, list):\n",
        "            dominant_emotion = analysis[0]['dominant_emotion']\n",
        "        else:\n",
        "            dominant_emotion = \"No face\"\n",
        "    except Exception as e:\n",
        "        print(\"Error in emotion analysis:\", e)\n",
        "        dominant_emotion = \"Error\"\n",
        "\n",
        "    # Put emotion text on the frame\n",
        "    cv2.putText(frame, f'Emotion: {dominant_emotion}', (30, 50),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "    # Convert BGR to RGB for display\n",
        "    display_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    img = Image.fromarray(display_frame)\n",
        "\n",
        "    # Display the image in notebook\n",
        "    clear_output(wait=True)\n",
        "    display(img)\n",
        "\n",
        "    # Add a short delay to simulate real-time (optional)\n",
        "    time.sleep(0.1)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "# Release the video capture object\n",
        "video_capture.release()\n",
        "print(\"Video capture stopped.\")\n"
      ]
    }
  ]
}